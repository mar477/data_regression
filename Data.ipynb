{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "Data = pd.read_csv(\"Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question No.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site_id with the largest number of unique users is: 5NPAU\n",
      "The number of unique users on the website is 544\n"
     ]
    }
   ],
   "source": [
    "# country_id = BDV (844 rows)\n",
    "Country_BDV = Data[Data.country_id == \"BDV\"]\n",
    "\n",
    "# Unique websites\n",
    "Country_BDV_unique_websites = Country_BDV.site_id.unique()\n",
    "\n",
    "# For each website (unique), count the unique number of user_id\n",
    "\n",
    "Site_Unique_Websites_Count = [] #Empty array to store \n",
    "Site_Unique_Websites = [i for i in Country_BDV_unique_websites] # Array of unique websites\n",
    "\n",
    "for i in Country_BDV_unique_websites:\n",
    "    Site_Unique_Websites_Count.append(len(Country_BDV[Country_BDV.site_id == i].user_id.unique()))\n",
    "\n",
    "print(\"Site_id with the largest number of unique users is: \" +\\\n",
    "      Site_Unique_Websites[np.argmax(Site_Unique_Websites_Count)])\n",
    "print(\"The number of unique users on the website is \" + str(max(Site_Unique_Websites_Count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question No.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "After_Time = Data[Data.ts >= \"2019-02-03 00:00:00\"] # After 2019-02-03 00:00:00\n",
    "Time_Range = After_Time[After_Time.ts <= \"2019-02-04 23:59:59\"] # Before 2019-02-04 23:59:59\n",
    "Users_Greater_10 = Time_Range.user_id.value_counts().to_frame() # Users by count\n",
    "Top_4_Users = Users_Greater_10[Users_Greater_10.user_id > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching users with sites\n",
    "Count = []\n",
    "Website = []\n",
    "Names = []\n",
    "for i in Top_4_Users.index:\n",
    "    Names.append(i)\n",
    "    Count.append(Time_Range[Time_Range.user_id == i].site_id.value_counts()[0]) # Count\n",
    "    Website.append(Time_Range[Time_Range.user_id == i].site_id.value_counts().index[0]) # Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: LC3A59, Count: 26, Website: N0OTG\n",
      "Name: LC06C3, Count: 25, Website: N0OTG\n",
      "Name: LC3C9D, Count: 17, Website: N0OTG\n",
      "Name: LC3C7E, Count: 15, Website: 3POLC\n"
     ]
    }
   ],
   "source": [
    "for y in range(4):\n",
    "    print(\"Name: \" + str(Names[y]) + \", Count: \" + str(Count[y]) + \", Website: \" + str(Website[y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question No.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5NPAU    992\n",
       "N0OTG    561\n",
       "QGO3G    289\n",
       "GVOFK     42\n",
       "3POLC     28\n",
       "RT9Z6      2\n",
       "EUZ/Q      1\n",
       "JSUUP      1\n",
       "Name: site_id, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User last visit\n",
    "last_visit = Data.groupby('user_id')['ts'].max().to_frame().reset_index()\n",
    "\n",
    "# merging to get site_id\n",
    "last_site = last_visit.merge(Data , on = ['ts','user_id'],how = 'left' )\n",
    "\n",
    "last_site.site_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question No.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of people who visited the same site first and  last is: 1670\n"
     ]
    }
   ],
   "source": [
    "# First and last times\n",
    "first_visit = Data.groupby('user_id')['ts'].min().to_frame().reset_index()\n",
    "last_visit = Data.groupby('user_id')['ts'].max().to_frame().reset_index()\n",
    "\n",
    "# First and last site (merge)\n",
    "first_site = first_visit.merge(Data , on = ['ts','user_id'],how = 'left')\n",
    "last_site = last_visit.merge(Data , on = ['ts','user_id'],how = 'left' )\n",
    "\n",
    "# Renaming columns\n",
    "first_site.columns = [\"user_id_x\",\"ts_x\",\"country_id_x\",\"site_id_x\"]\n",
    "last_site.columns = [\"user_id_y\",\"ts_y\",\"country_id_y\",\"site_id_y\"]\n",
    "\n",
    "# Last site (merge)\n",
    "merge_site = pd.concat([first_site,last_site],axis=1)\n",
    "print(\"Number of people who visited the same site first and  last is: \" +\\\n",
    "      str(len(merge_site[merge_site.site_id_x == merge.site_id_y])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
